# üß† Building Prompts for Agentic AI Systems 

Learn how to design effective prompts by breaking them into **modular components** like instruction, tone, role, and constraints. We'll walk through a real-world example ‚Äî improving a summary prompt step by step ‚Äî to demonstrate how each element contributes to clarity, consistency, and usefulness in real-world Agentic AI systems.

---

## üß∞ What You‚Äôll Get

* A breakdown of core and optional prompt components  
* A real-world example showing progressive prompt improvement  
* A modular, repeatable framework for building prompts in API-driven systems  
* Access to a [GitHub repository](#) and walkthrough video  

---

# üß© Designing Prompts That Work

A prompt like ‚ÄúSummarize this article‚Äù might work casually, but not reliably. In **Agentic AI**, where prompts are delivered through code or APIs, your prompts must be:

* Explicit  
* Repeatable  
* Aligned with the system's goal  

This lesson moves you from intuition-based prompting to **modular, configurable prompt design** ‚Äî the foundation for building **trustworthy AI systems**.

---

# üß± The Anatomy of a Prompt

Prompts consist of **modular components**. Think of these as interchangeable building blocks.

### ‚úÖ Core Components (Usually Required)

* **Instruction** ‚Äì What the AI should do  
* **Input** ‚Äì The data or content it should work with  

### üîß Optional (But Often Critical)

* **Context** ‚Äì Background that shapes the response  
* **Output Format** ‚Äì Desired structure (e.g., paragraph, bullet points)  
* **Role/Persona** ‚Äì Who the AI is acting as  
* **Constraints** ‚Äì Limits on tone, length, style  
* **Tone/Style** ‚Äì How the AI should sound  
* **Examples** ‚Äì Sample outputs  
* **Goal** ‚Äì The intent or purpose of the response  

üìå **Key Insight:** These components become your prompt *template*. You can tweak individual parts without rewriting the entire prompt.

---

# üöß From Components to Real Prompts

Let‚Äôs walk through a real example using the publication:

**"One Model, Five Superpowers: The Versatility of Variational Auto-Encoders"**

* GitHub repo: [Check here](#)
* Model: `gpt-4o-mini` (release date: 2024-07-18)  
* Temperature: `0`  
* Environment: API calls (stateless, no memory)

---

# üß™ Prompt Walkthrough: Step-by-Step Improvements

Let‚Äôs walk through how a simple prompt evolves into a precise, purpose-driven instruction set by adding modular components one at a time.

---

## üîπ Example 1: The Baseline (Instruction + Input Only)

Let‚Äôs begin with the most basic approach ‚Äî just an **instruction** and the **content**.

### üßæ Prompt
![prompt1](https://app-cdn.readytensor.ai/publications/resources/hubId=3/publicationId=2475/prompt-exampl1.jpg?Expires=1751113883&Key-Pair-Id=K2V2TN6YBJQHTG&Signature=AQX-Tkb5CcjoAaxzf5SQYxq9HB97ydxmzGGKhaAyaZIPOr5rCksupRGRHcRoYm25qg9O~tcJqvXb9KbnhSQ-8Gf2C3FsLJma-D0DY7ZlirNEBixXEcCs2gIu4v7IM68YoyDJWeCr6AFpbYDTAcZ6hiZrO-PpXwBWEIfm3XSIS7snsg5MeJZROHdYOW9f9Yvhw5lWR88de7dkkhSyI-TBYtwM16ZCXTzV1GlAIPOdJuDUJI1ZeLLHFrTzgour74pqdN3CHE5zFrh6hySN89eiHekoJiu~ZiNF0Dlo15fzUToZOxDZ-4o~mMz0Gqdu1ljzpUJkZfzaWXRInx~N2pQUhQ__)

You might notice we're using lead-in phrases like "Your task is as follows:". This may seem unnecessary now, but it will become clear why as we start adding more prompt elements. These separators help create clear boundaries between different components for the LLM to parse effectively.

### The response we get:

``` bash
The article titled "One Model, Five Superpowers: The Versatility of Variational Autoencoders" explores the capabilities of Variational Autoencoders (VAEs), a significant model in deep learning and machine learning. VAEs are highlighted for their versatility in various applications, including data compression, noise reduction, synthetic data generation, anomaly detection, and missing data imputation, with practical demonstrations using the MNIST dataset of handwritten digits.

The publication begins by explaining the fundamental architecture of VAEs, which consists of an encoder that compresses input data into a probabilistic latent space and a decoder that reconstructs the original data from this compressed representation.

The article emphasizes the advantages of VAEs over traditional autoencoders, particularly their ability to generate new data and handle complex distributions.

Key applications of VAEs are detailed, showcasing their effectiveness in:
1. Data Compression : VAEs can significantly reduce the dimensionality of data while preserving essential features, as demonstrated with MNIST images.
2. Data Generation: After training on the MNIST dataset, VAEs can generate new, similar digits by sampling from the latent space.
3. Noise Reduction: VAEs effectively reconstruct clean images from noisy inputs, enhancing data usability.
4. Anomaly Detection: By modeling normal data distributions, VAEs can identify outliers based on reconstruction loss.
5. Missing Data Imputation: VAEs can infer and reconstruct missing parts of data, making them suitable for handling incomplete datasets.

The article also compares VAEs with Generative Adversarial Networks (GANs), highlighting their respective strengths and weaknesses. VAEs are noted for their stability and versatility, making them suitable for tasks requiring both generation and reconstruction capabilities.

In conclusion, the publication encourages further exploration and experimentation with VAEs, emphasizing their transformative potential in various domains of research and industry. The article serves as a comprehensive guide for AI/ML practitioners looking to leverage VAEs in their work.
```


The problem:
It's way too lengthy for our purpose. The response is over 250 words and spans multiple paragraphs with bullet points. If we want something concise - say, one paragraph of about 80-100 words - we need to be more specific about our requirements.
This leads us to our first improvement: adding output constraints.

---
## üîπ Example 2: Adding Output Constraints

Now let's address the length issue by adding output constraints to our prompt. We'll specify exactly what format and length we want.

### Our updated prompt:
![prompt2](https://app-cdn.readytensor.ai/publications/resources/hubId=3/publicationId=2475/prompt-example2.jpg?Expires=1751113883&Key-Pair-Id=K2V2TN6YBJQHTG&Signature=apcFb-mgl17VKs73XZydf-i6Td91fNtVf9O-ODJFSiq7kQ6s71WtfqCkRr5qmMUTC0utNg5wTy2xSvUtfcUm7S6Y652a6ZMjmYmIVpq1g0E6VqguNJx51yS3qBDe58~2tTBfOir1hx5OQAOJM2Uy9Tj~VFcbdgLie1jH0rlVMWX5gne7NHI42TfI~o8~xz1L~AkhkrAiKaHhjryJmvKFSdA6BWLG61kElgqx9VvLm5HQySD6tz-dKF5LD801Tez11zHYtS1GwQ3MgswyhwGIL6oQFIdHOaLM9OicGgq5j1cIW1Jr67gW73HJLaO8qMo-R~DKkf26Bq6ZVCQGgh73CA__)

### The response we get:
```bash
The article "One Model, Five Superpowers: The Versatility of Variational Autoencoders" explores the multifaceted applications of Variational Autoencoders (VAEs) in deep learning, particularly using the MNIST dataset.

It highlights five key capabilities: data compression, synthetic data generation, noise reduction, anomaly detection, and missing data imputation.

The publication details the architecture of VAEs, emphasizing their probabilistic encoding and generative abilities, which distinguish them from traditional autoencoders.

By providing practical examples and implementation insights in PyTorch, the article encourages AI/ML practitioners to leverage VAEs for diverse machine learning challenges, showcasing their transformative potential across various domains.
```
### This is much better!
The LLM definitely addressed what we asked for - we got a single paragraph that's about 95 words, with no bullet points or headers. The constraints worked exactly as intended.

### The remaining issue
While the length and general format is now correct, the language feels quite formal and academic. Notice phrases like "multifaceted applications," "transformative potential," and "diverse machine learning challenges." If this summary is intended for a broader audience, we need to consider both who is writing this and who it's for.

This leads us to our next improvement: adding a role or persona to establish who the AI should embody as the writer and who the intended audience is, which will guide both the messaging and communication style.

----

## üîπ Example 3: Adding a Role/Persona


Now let's address the messaging and communication style issue by adding a role or persona to guide how the AI should communicate.

### Our updated prompt:
![prompt3](https://app-cdn.readytensor.ai/publications/resources/hubId=3/publicationId=2475/prompt-example3.jpg?Expires=1751113883&Key-Pair-Id=K2V2TN6YBJQHTG&Signature=Xd3TxD-Y2hrqycs91cG8wUgK3dvcGAU86mywHz5yP6f7vAYrYhTF3REoUL0wgDXaZkGEtQGFRtIenr5nelgDyjr7zae5U-T3xAKy3naEA~61Vwkl3-kKvWn5XRRmkNLEhj3M2WTltYYz-2gctIj2ZFSxIilaJscoZAb73kGitwJ6DNpS-wcmm~0MRbmb2pvQNhxZme-vJ-tsQGWwmrnBRY5dggjWGRcTzjZYPtOMllKGie6Uk3JeHMqHl46WplNDb1s51vsSfnB7kHnlsJSw27TdA7TW7BSxHvgcxwxaDczYiV3U3WoJ3-Q~8ALpaplu71f3Ur3GgKHmXbier9BlDw__)

### The response we get:
```bash
The article discusses Variational Autoencoders (VAEs), which are flexible models used in machine learning for various tasks. VAEs can compress data, generate new data, reduce noise, detect anomalies, and fill in missing data.

The publication uses the MNIST dataset of handwritten digits to illustrate these applications.

It explains how VAEs work, including their unique probabilistic approach, and compares them to traditional autoencoders.

The article encourages further exploration of VAEs, emphasizing their potential in both research and practical applications across different fields.
```
### Great improvement!
The language is noticeably more accessible. Gone are the overly formal phrases like "multifaceted applications" and "transformative potential." Instead, we get clearer language like "flexible models" and "various tasks." The role guidance successfully shifted the writing toward a general audience.
### What's still missing:
While the communication approach is better, the writing still feels somewhat generic and polished in a way that doesn't quite feel human or personal. The language, while clearer, still has that "AI-generated" quality with phrases that feel a bit stiff or overly neutral.

This brings us to our next refinement: adding specific style and tone guidelines to create a more natural, engaging voice.

----

## üîπ Example 4: Adding Style and Tone Guidelines

Now let's refine the voice further by adding specific style and tone guidelines to create more natural, engaging communication.


### Our updated prompt:
![prompt4](https://app-cdn.readytensor.ai/publications/resources/hubId=3/publicationId=2475/prompt-example4-v2.jpg?Expires=1751113883&Key-Pair-Id=K2V2TN6YBJQHTG&Signature=xldizTfaX1aKt8iSnERa67fb-qfOXkZ8W07A81RLTXnOsoqgfcD-BTNFnQm0u34jxeo771T2jjPu2p5hPNwR0JumPsIg8m9laY7nu8acBj3m4bV8WwQFGmzJnwTr7Eo947NeJ0Q8ZDTiRkW9Tlk~nQuPndIAQg-gDm~iFlXn16gLO-oB-8FWhs2GeVxFqUEvFyx~GcTNHFTFQAZqrbnCORdn7ExJfv81jTfW8h4RVD6mziTKE4LY3-U3j3084pHznWSmAzhikHbKzuH~YAfduQELmLLUYyHfMMHA9oaQhnx1cccXIrl44xXqoIfXrpPivk4oN1X~szuvEWesfmQw5Q__)

### The response we get:
```bash
The article discusses Variational Autoencoders (VAEs), which are flexible deep learning models used for various tasks like data compression, noise reduction, data generation, anomaly detection, and missing data imputation.

It explains how VAEs work by encoding data into a compressed format and then decoding it back, using the MNIST dataset of handwritten digits as a practical example.

The publication emphasizes the advantages of VAEs over traditional methods, particularly their ability to generate new data and handle complex distributions.

It encourages further exploration and experimentation with VAEs in different fields, highlighting their broad applicability in machine learning.
```

### What changed:
In this short paragraph, the differences may not be immediately perceptible compared to the previous version. However, these style guidelines matter significantly when processing large volumes of requests - they help ensure consistency and prevent the AI from slipping into overly promotional or buzzword-heavy language that sometimes creep in.
### The remaining gap:
While we've improved the format, tone, and style, we haven't been explicit about the purpose of this summary. Are we trying to help someone decide whether to read the full article? Are we creating a reference for documentation? The intended outcome shapes how we prioritize and present information.


Let‚Äôs wrap it up by adding the final component: a clear goal to align the summary with its purpose.

----
## üîπ Example 5: Adding a Clear Goal

Finally, let's add a goal to make the summary's purpose explicit and guide how information should be prioritized.



### Our updated prompt:
![prompt5](https://app-cdn.readytensor.ai/publications/resources/hubId=3/publicationId=2475/prompt-example5-v2.jpg?Expires=1751113883&Key-Pair-Id=K2V2TN6YBJQHTG&Signature=UgKfd4YBDs0XT-ueeHweN8h3MQ~-4dGveD7uN73na5pCusk7N6cp5Zef~R~cq5hW18IeGFb6vfzZF9QIVqbVtza70e6uS3hQAxVC6RzAaGYBwP5e8tCoUCu06qmPMGLb38p3FJKFvXzhXllGmQxFaxET3x~wlTcjM9LsFktx8bEyM1DiO1bp0OagG5ZgUDsJF8IyTT8aMi8tC70~lcTwIQEOxmxGxM09k8BjUhSbV6y8wuOUlRnnOvQ3Fl5mf1DqXEO9DtastBJ0ZGNpOhqqlxQvCjXcWqw7ERfd8chxmISe6bBS6WgP0sBriHqUoLErakmQ2t4c3ACqrtytw3yxBw__)

### The response we get:
```bash
The article discusses Variational Autoencoders (VAEs), a type of deep learning model known for their flexibility in handling various tasks.

It highlights five main applications: data compression, data generation, noise reduction, anomaly detection, and missing data imputation, using the MNIST dataset of handwritten digits as a practical example.

The publication explains how VAEs work, including their unique probabilistic approach, and provides insights into their implementation in PyTorch. 

It also compares VAEs with traditional autoencoders and GANs, emphasizing their advantages in stability and versatility.

This resource is valuable for anyone interested in understanding and applying VAEs in machine learning.
```
### Putting It All Together
Notice how the summary now ends with an explicit recommendation about the publication's value. The goal guidance shifted the focus toward helping someone make a decision about whether to invest time reading the full article.

# The Power of Prompt Modularization

Each enhancement we made corresponds to a specific prompt component. Here‚Äôs a quick summary of what we added, why it matters, and when it showed up:

| **Component**     | **Purpose**                                | **Introduced In** |
|------------------|---------------------------------------------|-------------------|
| Instruction       | Defines the task for the AI                | Example 1         |
| Output Constraints| Controls format, length, or structure      | Example 2         |
| Role/Persona      | Sets the voice and audience perspective    | Example 3         |
| Style & Tone      | Guides how the AI communicates             | Example 4         |
| Goal              | Aligns the output with the intended purpose| Example 5         |

This modular approach gives you granular control over each aspect of the AI's behavior, and just as importantly, it makes your prompts configurable and reusable. Instead of hard-coding every new prompt, you can mix and match components depending on the task, audience, or context.

Want a different tone? Swap in a new style guideline. Need a different format? Adjust the constraints or add output formatting instructions. Want to shift the intent of the output? Just update the goal ‚Äî no need to rewrite the entire prompt.

You‚Äôre not crafting one-off prompts; you‚Äôre building a scalable system ‚Äî a prompt design library you can plug into any future Agentic AI project. This lesson covered just a few components, but others, like context blocks, examples, and response format specs, fit naturally into the same approach. Together, they form a flexible, powerful foundation for scalable AI development.


